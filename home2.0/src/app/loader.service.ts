import { Injectable } from '@angular/core';
import { Http, HttpModule, Headers, URLSearchParams } from '@angular/http';
import 'rxjs/add/operator/toPromise';
import { mapValues, keys, mapKeys, values, trim, uniq, toPairs } from 'lodash';
import { DomSanitizer, SafeResourceUrl, SafeHtml } from '@angular/platform-browser';
import * as _ from 'lodash';
import * as d3 from 'd3';
import * as bibtexParser from 'bibtex-parser';

// can be customised to be sensitive to target.
// pass in function that will generate keys for the cache:
// e.g. if values varies on multiple parameters, then return
// a concatenation of dependent values
export let memoize = (f: (...args: any[]) => string) => {
  return function (target: Object, propertyKey: string, descriptor: TypedPropertyDescriptor<any>) {
    const retval: { [method: string]: any } = {}, method = descriptor.value;
    descriptor.value = function (...args: any[]) {
      const cache_key = propertyKey + (f !== undefined) ? '_' + f.apply(null, args) : '';
      if (retval[cache_key]) {
        return retval[cache_key];
      }
      return retval[cache_key] = method.apply(this, args);
    };
  };
}

/* generated by pandoc */
export class Author {
  family: string;
  given: string;
}

enum EntryType {
  article, // = 'ARTICLE',
  inproc, // .. = 'INPROCEEDINGS',
  misc, // = 'MISC',
  techreport, // = 'TECHREPORT',
  phdthesis//  = 'PHDTHESIS'
}

export class BibEntry {

  author: Author[];
  entrytype: EntryType;
  title: string;
  booktitle?: string;
  year?: string;
  organization?: string;
  publisher?: string;
  type: string;
  containerTitle?: string;
  issued?: ({ [key: string]: number[][] });

  constructor(raw_src_json: any) {
    if (raw_src_json)  {
      raw_src_json = _.clone(raw_src_json);
      if (raw_src_json.AUTHOR) {
        // split authors
        raw_src_json.AUTHOR = raw_src_json.AUTHOR.split(' and ')
          .map((name) => ({ family: name.split(',')[0], given: name.split(', ')[1] }));
      }
      raw_src_json = _.mapKeys(raw_src_json, (vv, kk) => kk.toLowerCase().split('-').map((x) => x.trim()).join(''));
      raw_src_json = _.mapValues(raw_src_json, (vv, kk) => {
        if (typeof vv === 'string') {
            // gets rid of accents in values
            return vv.replace(/\{\\\'(.)\}/g, '$1').replace(/\\(.)/g, '$1');
        }
        // now let's get rid of accents in authors, like paul andr√© <3
        if (kk === 'author') {
            return vv.map((author) => _.mapValues(author, (vva, kka) => vva && vva.replace(/\{\\\'(.)\}/g || '', '$1')));
        }
        if (kk === 'title') {
          if ('.?!'.indexOf(kk.slice(-1)[0]) < 0) {
            return vv + '.';
          }
        }
        return vv;
      });
      _.extend((this as any), raw_src_json);
    }
  }
}

export class Project {
  id: string;
  title: string;
  theme: string;
  pubids: string[];
  pubs: (BibEntry | CrossRefItem)[];
  images: string[];
  headimg: string;
  color: string;
  summary: string;
  summaryHtml: SafeHtml;
}

export class NewsItem {
  id: string;
  datestr: string;
  date: Date;
  summary: string;
  summaryHtml: SafeHtml;
}


export class CrossRefAuthor {
  given: string;
  family: string;
  affiliation: string;
}
export class CrossRefDate {
  timestamp: number;
  datetime: string;
  dateparts: number[];
}
export class CrossRefEvent {
  acronym: string;
  location: string;
  name: string;
  start: CrossRefDate[];
}
export class CrossRefItem {

  author: CrossRefAuthor[];
  DOI: string;
  type: string;
  title: string[];
  created: CrossRefDate;
  containertitle: string[];
  ISBN: string[];
  url: string;
  linkUrl: string;
  event: CrossRefEvent;
  publishedprint: CrossRefDate[];

  constructor(loader: LoaderService, raw_src: any) {
    if (raw_src) {
      // src is incoming raw json
      const top = loader.undashifyKeys(raw_src);
      let l1 = _.mapValues(top, loader.undashifyKeys);
      l1 = loader.unzeroObj(l1);
      if (l1.link && l1.link.URL) {
        this.linkUrl = l1.link.URL;
      }
      _.extend((this as any), l1);
    }
  }
}
@Injectable()
export class LoaderService {

  constructor(private httpM: HttpModule, private http: Http, private sanitiser: DomSanitizer) {

    // debug only ================================>
    this.getBibTex().then((library) => console.log('bibtex debug ', library));
    this.getCrossRef().then((library) => {
      console.log('crossref debug ', library);
      _.map(library, (pub, doi) => {
          console.log(doi, ' => ', pub.title, pub.publishedprint && pub.publishedprint[0] && pub.publishedprint[0].datetime);
      });
    });
    // 
  }

  // @memoize((x) => x)
  // getPubs(): Promise<BibEntry[]> {
  //   return this.http.get('assets/bibtex.json').toPromise().then(response => {
  //     return response.json().map(this._inPub);
  //   });
  // }

  // mixin'
  @memoize((x) => x)
  getPubs(): Promise<{[x: string]: BibEntry|CrossRefItem}> {
    return Promise.all(
      [
        this.getBibTex(),
        this.getCrossRef()
      ]
    ).then(libraries => _.extend(libraries[0], libraries[1]));
  }

  // CrossRef Loader
  @memoize((x) => x)
  getCrossRef(): Promise<{[x: string]: CrossRefItem}> {
    return this.http.get('assets/crossref.json').toPromise().then(response => {
      const rj = response.json();
      return rj && rj.message && rj.message.items;
    }).then((items) => {
      console.log('items', items);
      let mine = items.filter((item) =>
        item.author.filter((a) => a && a.given && a.given.toLowerCase().trim() === 'max' &&
          a.family && a.family.trim().toLowerCase().match(/van[\W]*kleek/)).length > 0);

      mine = mine.map((item) => new CrossRefItem(this, item));

      return mine.reduce((obj, a) =>  {
          const key = a.DOI;
          if (!key) { console.error('no DOI for ', a, ' -- skipping'); return obj; }
          obj[key] = a;
          return obj;
        }, {});
    })
  }

  unzeroObj(o: any) {
    return _.mapValues(o, (v, key) => {
      if (key === 'author') { return v; };
      return v && typeof v === 'object' && (!_.isArray(v) || v.length == 1) && v[0] ? v[0] : v;
    });
  }

  // BibTex loader
  @memoize((x) => x)
  getBibTex(): Promise<{[x: string]: BibEntry}> {
    return this.http.get('assets/bibtex.bib').toPromise().then(response => {
      let parsed = bibtexParser(response.text()) as {[key: string]: any};
      parsed = _.mapKeys(parsed, (v, k) => k.toLowerCase());
      return _.mapValues(parsed, (v, k) => new BibEntry(v));
    });
  }

  undashifyKeys(ii) {
    if (_.isArray(ii) || typeof ii !== 'object') { return ii; }
    return _.mapKeys(ii, (v, k) => {
      return k.split('-').map((x) => x.trim()).join('');
    });
  }
  _inPub(ii): BibEntry {
    return _.mapKeys(ii, (v, k) => {
      return _.map(k.split('-'), (kword, i) => i > 0 ? kword.toUpperCase() : kword).join('');
    }) as BibEntry;
  }

  getProjects(): Promise<Project[]> {
    return this.getPubs().then((by_bibid) => {
      return this.http.get('assets/proj.json').toPromise().then(response => {
        return response.json().projects as Project[];
      }).then((ps) => {
        ps.map((p) => {
          p.color = d3.interpolateRainbow(1.0 * ps.indexOf(p)/ps.length);
          if (p.summary) { 
            p.summary = ['<p>', p.summary.replace(/\n/g, '</p><p>'), '</p>'].join('');
            p.summaryHtml = this.sanitiser.bypassSecurityTrustHtml(p.summary);
          }
          if (p.pubids) {
            p.pubs = p.pubids.map((pubid) => by_bibid[pubid] || undefined).filter((x) => x);
          }
          (window as any).d3 = d3;
        });
        return ps;
      });
    });
  }

  getNews(): Promise<NewsItem[]> {
    return this.http.get('assets/news.json').toPromise().then(response => {
      return response.json().news as NewsItem[];
    }).then((news) => {
      news.map((n) => {
        n.date = new Date(n.datestr);
        n.summaryHtml = this.sanitiser.bypassSecurityTrustHtml(n.summary);
      });
      news.sort((a, b) => b.date.valueOf() - a.date.valueOf());
      return news;
    });
  }
}
